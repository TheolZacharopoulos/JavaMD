% !TEX root = ../thesis.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapter: Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation}\label{Evaluation}

Having presented evidence that our framework is able to solve the problem of \ac{ccc} (Chapters \ref{Example Application} and \ref{AspectRefactoring}) we will now evaluate our claims.
In this chapter we present an evaluation of our contributions in implementing aspects with managed data, in relation to our research questions.

\section{Research Questions and Answers}\label{Research Questions and Answers}
In Chapter \ref{Introduction} we stated three research questions which were the main focus of this thesis.
These are answered as follows:

\paragraph{How to implement managed data in a static language?}
From our managed data implementation in Java, presented in Chapter \ref{Implementation}, we conclude that it is possible to implement managed data in a static programming language by using Reflection and Dynamic Proxies.

\paragraph{Can managed data solve the problem of crosscutting concerns?}
We argue that by using data managers, managed data can implement aspects of data in a modular way.
As presented in both Chapters \ref{Example Application} and \ref{AspectRefactoring}, managed data can handle aspects and solve the problem of \acrlong{ccc}.
Additionally, we have collected a set of metrics that assess our implementation in relation to the original.
In this chapter we discuss the results of those metrics extensively.

\paragraph{To what extent can managed data handle an inventory of aspects in the JHotDraw framework, compared to the original and the Aspect Oriented implementation?}
The results of our aspect refactoring in Chapter \ref{AspectRefactoring} show that managed data can handle aspects of JHotDraw. 
In addition, we claim that our solution extends some of the capabilities of the AJHotDraw implementation.
However, in this chapter, we provide further evaluation of our aspect refactoring and we compare it with the \acrlong{aop} solution in terms of a list of ``modularity properties'' and metrics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Metrics
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Assessment Framework}\label{Assessment Framework}
In this section we discuss the summary of those results presented in Table \ref{tbl:metrics}.

% #important
\subsection{Metrics Interpretation}

\paragraph{Coupling.} Although the numbers of \acrlong{dit} are similar in the two systems, the reasons are not the same.
In the case of the JHotDraw the classes have higher \ac{dit} because they implement interfaces that define concerns.
This is not the case in MDJHotDraw; however, the high number of \ac{dit} is due to the data managers stacking process.
Additionally, the specifications are described in interfaces implemented by data managers which also increases the \ac{dit}.
However, the coupling is between specifications and data managers and not \ac{ccc} and components.

The \acrlong{cbc} metric is also similar in both versions.
Again, the reasons differ for each case.
\ac{cbc} in JHotDraw increased from the coupling between main components and \ac{ccc}.
In the case of MDJHotDraw there is not such coupling but there is coupling between data managers and their specifications.

The coupling overall number in MDJHotDraw is similar to JHotDraw; however, for totally different reasons.
JHotDraw components are coupled with the \ac{ccc}, while MDJHotDraw data managers are coupled with their specifications.
Therefore, data managers are not coupled with the application logic since they are abstract and reusable.
This solved the evolution paradox \cite{tourwe2003existence} problem observed in \ac{aop}, where the aspects are closely coupled with the components since the aspects have to know about the components.

\paragraph{Size.} The \acrlong{vs} metric is higher in the case of MDJHotDraw since, although the concern-related components have been removed, more components have been added for the managed data migration.
Those components are schema factories and helpers that altogether migrate the system to managed data.

As a result, the \acrlong{loc} metric is higher for the MDJHotDraw version since more components have been added.

The \acrlong{woc} metric is similar in both cases.
The reasons are that no significant changes have been made in terms of component complexity and the code remained similar to the original one.
Small fluctuations on the numbers indicate that complexity increased or decreased by the data managers code in the MDJHotDraw case.

Finally, the \acrlong{noa} metric is almost identical in both cases.
The reason is that attributes that were related to the concern in JHotDraw have now moved to specifications and fields in low-level data managers in MDJHotDraw.

In general, the size of the two systems is similar with a small increase in the MDJHotDraw owing to the fact that a few components have been added during the migration to managed data process.

\paragraph{Cohesion.} The \acrlong{lcom} metric values are lower on the MDJHotDraw case.
Although the implementation of the point-cuts in managed data is performed using interfaces and this affects the \ac{lcom} metric of the concrete implementation classes, the value is still lower than JHotDraw.
This is mainly because of the managed data migration.
During this process we tried to improve the cohesion of the managed data definition by separating non-managed data from managed data as much as possible.

\paragraph{Separation Of Concerns.} Finally, the following metrics measure the scattering and tangling of code in the two versions.
First, both \acrlong{cdc} and \acrlong{cdo} metrics measure the code scattering in the systems.
The differences in these two metrics are significant since the managed data version explicitly focuses on removing scattered code from the original and moving the concern code in data managers.
Especially the \ac{cdo} metric, which measures the operations that assist the implementation of a \ac{ccc}, is notably lower because those operations are now located in data managers.
Second, the \acrlong{cdloc} metric measures the code tangling of the systems.
The MDJHotDraw has a remarkably lower number owing to the fact that every concern-related code has been removed completely from the application classes.
The only place that \ac{cdloc} exists is in the integration points of the clients classes.
More specifically, the places that define the usage of this concern by using the proper data manager.

In general, scattering and tangling metrics are significantly low in the case of MDJHotDraw.
This is because we have explicitly moved the concern-code from the classes to reusable data managers.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modularity Properties}\label{Eval Modularity Properties}

In order to make an assessment of our research in comparison with the \ac{aop} version, we applied the same software quality metrics presented by Hannemann et al. \cite{hannemann2002design} in their design patterns refactoring.
More specifically, the authors refer to those metrics as ``closely-related modularity properties'' and use them to analyze and evaluate their design pattern solutions in AspectJ.

Since our solution of the observer pattern concern in JHotDraw refers to the same issue that Hannemann et al. \cite{hannemann2005role} describes, we concluded that using the same modularity metrics will lead to a more reliable assessment of our solution and a more definitive assessment of our designs.
The focal modularity properties are: \textit{Locality}, \textit{Reusability}, \textit{Composition transparency} and \textit{(Un)pluggability}. 

\subsection{Modularity Properties in the Observer Pattern}

In their \textit{Observer} pattern refactoring in AspectJ, Hannemann et al. \cite{hannemann2005role}, along with Marin et al. \cite{marin2005approach} who used the same refactoring method in AJHotDraw, assess their results using these four modularity properties.

\subsubsection{Locality}
As shown in the \ac{aop} solution, the code that implements the observer pattern is in concrete observer aspects, nothing is scattered in the participant classes. 
Thus, all the participants are free of the pattern context and there is no coupling between the participants \cite{hannemann2005role}.
However, as the \ac{aop} evolution paradox suggests \cite{tourwe2003existence}, the aspects themselves are strongly coupled to the application's code.

Likewise, in the \textit{managed data} version, \textit{Subject} and \textit{Observer} classes are pattern agnostic.
However, those classes are not aware of their pattern properties since they have been attached later by a subject role data manager.

\subsubsection{Reusability}
In the \ac{aop} version, the core pattern code is abstract and reusable. 
They have implemented abstract aspect code that explicitly refers to an observer pattern generalized implementation.
This has been defined as an abstract aspect and it can be reused and shared across multiple observer pattern instances \cite{hannemann2005role}.
That leads to a modular solution, although the concrete aspects still are highly coupled with the application's code.

Similarly, in the \textit{managed data} version, we have implemented the observer pattern as a reusable data manager.
More specifically, the \texttt{SubjectRole} data manager is an abstract observer pattern that can be reused in any case.
Moreover, the definition of this data manager is independent from the object's structure.
No coupling between the application and the observer pattern implementation exists.
The only ``case-specific'' functionality is the consistent behavior, which is similar to the one presented in the \ac{aop} solution, although, our solution supports conditional pointcuts.
Additionally, the managed data version defines the pointcut in an explicit interface, separating the general observer from the specific consistent behavior.

\subsubsection{(Un)pluggability}
In the \ac{aop} version, since \textit{Subjects} and \textit{Observers} do not need to be aware of their role in any pattern instance, it is possible to switch between using a pattern and not using it in the system \cite{hannemann2005role}. 

The \textit{managed data} version, takes this a step further.
It allows the programmer to ``plug'' or ``unplug'' specifications of the pattern by simply creating managed objects, using the preferable data manager with or without the specifications for the pattern.
One can switch to the pattern implementation by creating objects provided by the subject role data manager, or simply by the basic data manager, which would lead to a non-observable object.
Furthermore, this (un)pluggability can be enabled in data managers composition level, by stacking data managers, something we have applied in the subject role and pointcut case.

\subsubsection{Composition transparency}
In the \ac{aop} version, a pattern's participants are not coupled to the pattern, neither to the abstract aspects.
Therefore, if a \textit{Subject} or an \textit{Observer} takes part in multiple observing relationships, their code does not become more complicated \cite{hannemann2005role}.
However, the composition becomes more complicated in the join-points, since such an aspect implementation has to include multiple roles.

In the \textit{managed data} version, we can implement such a thing in various ways.
First, we can choose the \ac{aop} approach, by implementing a generalized data manager for the pattern and concrete data managers for each implementation.
Alternatively, we could implement a data manager which implements a set of specifications that result to the composition of patterns.
Such solution would lead to a separate specification definition that describes a composition of patterns.
Consequently, the final system will be simple and (un)pluggable since the composition is transparent in a data manager.

\subsection{Unpluggability of the Undo Concern}
In order to evaluate the \ac{ccc} refactoring of ``Undo'' Marin \cite{marin2004refactoring} used the (Un)pluggability property. 
The author groups the complexity of the commands based on two criteria.
First, on the degree of \textit{tangling} of the undo setup in the command's logic, specifically the activity's \texttt{execute()}method. 
Second, on the impact of removing the undo-related part from its original site, which can be estimated by the number of references to the factory method and to the methods of the nested undo activity.
Thus, the (un)pluggability property gives a measure of how clearly the concern is distinguished in the original code and is a good estimate of the refactoring costs.

In the \ac{aop} version of the \texttt{ChangeAttributeCommand} the refactoring is considered successful.
First, the \texttt{UndoActivity} nested class, accompanied by its factory method, is removed from the command's code.
Next, the accessors of the \texttt{UndoActivity} are inherited from top level classes and not overridden locally.
Finally, the undo related code in the nested classes is \textit{unpluggable} and suitable for extraction and refactoring.

Likewise, the managed data version followed the same unpluggability principles as the \ac{aop} version.
Following the similar design we managed to achieve the same level of unpluggability.
However, in this case the methods related to the crosscutting functionality of undo have not been defined by top level classes but by a set of stacked data mangers.
Additionally, in managed data the \texttt{UndoActivity} is not defined based on naming conventions like in AspectJ, but through a nested private class definition dedicated to the command-specific data manager.

The overall assessment of the modularity properties presented in this section is summarized in Table \ref{tbl:Modularity Properties}.

\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
	\begin{tabular}{@{}lll@{}}
	\toprule
	\textbf{Modularity Property} & \multicolumn{1}{c}{\textbf{AJHotDraw}} & \multicolumn{1}{c}{\textbf{MDJHotDraw}} \\ \midrule
	\textbf{Locality} & + CCC implemented in aspects & + CCC implemented in data managers \\ \midrule
	\multirow{3}{*}{\textbf{Reusability}} & + Abstract aspects & + Abstract data managers \\
	 & - Pointcuts for concern-specific & - Pointcuts for concern-specific \\
	 & - Not Flexible (Name conventions, no conditions) & + Flexible (No conventions, state in DMs) \\ \midrule
	\textbf{(Un)pluggability} & + Easy to plug and unplug (Defined in aspect) & + Easy to plug and unplug (Change data manager) \\ \midrule
	\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Composition \\ Transparency\end{tabular}}} & + Easy to be part on more than one patterns & + Easy to be part on more than one patterns \\
	 & - Complicated in join-points (multiple role aspects) & + Easy on join-points (stack data managers) \\ \bottomrule
	\end{tabular}}
\caption{Modularity Properties}
\label{tbl:Modularity Properties}
\end{table}

\section{Discussion}\label{Evaluation Discussion}
In this section we provide a discussion of the overall findings during the development of this thesis.

\subsection{Managed Data Implementation}
One of the advantages of our managed data framework is the simplicity of its usage. 
The programmer simply needs to define the schemas, followed by their factories and data managers, can easily write a program using them.
The framework takes care of the \textit{parsing}, \textit{interpretation}, \textit{type checking} and any other underline mechanisms.
Moreover, it uses Java concepts, which makes it safer in terms of type checking and definitions resulting to an easier, for Java developers, adaptation.
Furthermore, by being a self-describing language it is no longer bounded to the Java constructs transforming everything into managed data.
Finally, the effortless mechanism of stacking data managers makes it significantly modular on every level, meta or not.

However, there is a number of implementation issues described in Section \ref{Implementation Issues}.

Another issue that arises is that integration in existing systems is complicated considering every model has to be redefined as a schema and every functionality has to be reimplemented in data managers.
An existing system integration is presented in Chapter \ref{AspectRefactoring}.

\subsection{Managed Data Evaluation}
Managed data is able to successfully handle aspects in a system.
However, the following issues should be acknowledged:

\subsubsection{Modularity}
First, the modularity of data managers and their abstract way of data manipulation makes the implementation of aspects very simple and extensible.
More specifically, implementing \textit{components} (non-crosscutting concerns) as managed data and \textit{aspects} (crosscutting concerns) by using specific data managers, one completely separates the two concepts.
Contrary to the \ac{aop} version, managed data does not couple the aspects with the application's components code.
The aspects are reusable data managers that can be plugged / unplugged and used in various concerns.
Certainly, there are application specific parts, such as pointcut definitions; however, by \textit{stacking} data managers we can support the application specific pointcuts at the lowest level.
As a result, we can claim that managed data does not entirely solve the \textbf{evolution paradox} \cite{tourwe2003existence}, but it exceeds \ac{aop} system in modularity.

\subsubsection{Flexibility}
Managed data can be used similarly to \ac{aop}; however, the flexibility of the language takes it a step further in some cases.
The design of the application is not bounded by the language, like in AspectJ's case.

AspectJ has limitations that can be one overcome by using managed data.
In particular, as shown, data managers allow to access the current object's state, while AspectJ's pointcuts implementation do not.
An object's state can be used for implementing functionalities depending on the current state of an object, for instance conditions in pointcuts.

Furthermore, \ac{aop} tries to discriminate methods based on some common structural properties such as particular coding conventions.
For instance, AspectJ's mechanisms do not allow introduction of nested classes; therefore in the case of the undo refactoring, the post-refactoring association was only an indirect one, based on naming conventions (``\texttt{UndoActivity}'').
This is a weaker connection than the one provided by the original solution.  
Additionally, what happens in case the conventions followed do not agree with the rules, or in case developers do not follow the desired conventions?
In other words, it is very difficult to capture the required join-points for the aspect weaver in a general and extensible way.
Managed data on the other hand do not require such conventions.
Since we have defined our data, its structure is accessible via the \texttt{schemaKlass} of the \texttt{MObject}, therefore we do not need any kind of conventions to determine the structure of properties.
Moreover, private classes in managed data is as easy to be defined as in the original version since \texttt{MObject} is just a class.
Therefore, no code conventions are needed.

\subsubsection{Performance}
In practice, since managed data has been implemented using Java reflection and Dynamic Proxies, it is unfavorable for applications that need performance to use it.
\ac{aop}, and specifically the \textit{aspect weaving} process, provides an oblivious way of dealing with aspects.
The weaver produces static Java code, which is then compiled in \ac{jvm} and can be optimized.
On the contrary, data managers dynamically analyze the schemas through reflection, which makes it a lot harder for the compiler to optimize. 
More specifically, even though the HotSpot \ac{jvm} has one of the best just-in-time compilers, Java's dynamic proxies introduce 6.5x overhead \cite{marr2015zero}.
Thus, \ac{aop} performance is much higher than managed data.
% A simple demonstration of the performance overhead introduced by managed data can be seen in Appendix \ref{appdx:PerformanceOverhead}.

\subsubsection{Migration and Integration}
Finally, both the migration and the integration of an existing application in the two cases has some trade-offs.

On one hand, the integration of an \ac{aop} version requires a whole new language (e.g. AspectJ) in line with the new concepts of the \ac{aop} paradigm.
A developer has to implement \textit{aspects}, \textit{advices}, \textit{join-points} and \textit{pointcuts}. 
In addition, the programmer has to setup AspectJ to the IDE of preference along with the programming environment.
After the environment has been set up, the migration of an existing application to the \ac{aop} paradigm is relatively easy.
Finally, a developer has to migrate the application using the aspect oriented language's concepts and the weaver will do the job.

On the other hand, the integration of managed data is very simple since it is pure Java.
No new language is required, no any additional IDE setup nor programming environment.
Additionally, although managed data introduces new concepts, it still uses the Java syntax, e.g. interfaces and annotations; therefore, the integration is a lot simpler.
It is relatively easy for a developer, who is familiar with Java, to learn the managed data concepts.
However, the migration of an existing application to managed data can be time consuming since a programmer has to migrate it from normal Java class definition  to managed data schemas definition (interfaces).
Additionally, some limitations arise from this migration because interfaces and classes do not explicitly support the same functionalities.
As seen, the framework has some limitations such as Java keywords, encapsulation of the methods in interfaces or class inheritance.
However, such definitions could be defined using annotations in future work.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Threats to validity
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Threats to Validity}
In this section we present a set of validity criteria including \textit{Construct}, \textit{Internal}, \textit{External} validity and \textit{Reliability} \cite{easterbrook2008selecting}.
% Construct Validity: Efficient interpretation of the results 
First, regarding the construct validity of this research, one should keep in mind that our results are compared to another research's findings. 
The AJHotDraw implementation may not be indicative of the overall AspectJ's capabilities in aspect refactoring nor was altered by us.
In other words our results focused on the comparison of our aspect refactoring in managed data with Marin's et al. AJHotDraw aspect refactoring.

% Internal validity: Study design
% External validity: Justified results (is it the right case?)
The internal and external validity of this thesis is satisfactory since our focus was narrowed to a representative case and predefined and tested metrics.
However, the AJHotDraw provides a more complete aspect refactoring of the original version.
For instance, in the undo concern case, AJHotDraw refactors all of its instances inside JHotDraw. 
% It separates the concerns removal on different levels of complexity, each of which has a different refactoring approach.
In our case we only refactored a part of the undo concern, in order to show how our framework will handle this aspect; a limited approach when compared to AJHotDraw's holistic implementation.
% Metrics:
We should keep in mind that the metrics we used have been introduced for both \ac{oop} and \ac{aop} systems.
However, in this thesis we used them in managed data implementation. 
% Tests
Furthermore, in order to evaluate the behavioral conservation of our refactoring we used JHotDraw's test suite.
Even though our code passes the tests, the suite is not complete and breaks in some files, even in the original version.
We proposed the creation of a new test suite, like AJHotDraw did with the TestJHotDraw project, as a potential solution to this problem.

% #Important
Additionally, one can argue that JHotDraw's \ac{ccc} could be refactored simply by using dynamic proxies, without the whole Managed Data modeling structure.
This is something that can be researched more; however, managed data besides the first class modeling they provide, they also have a modular design of aspect implementation.
This design makes it easy to write modular aspects of data using dynamic proxies.

% Reliability: same results on replication?
Finally, the reliability of this research can be problematic.
More specifically, the refactoring is strictly dependent on the programmer's design and unless our design is used when replicating this research, a different assessment could be reached.
% by repeating the refactoring one could come up with different design and therefore, conclude on different assessment.
